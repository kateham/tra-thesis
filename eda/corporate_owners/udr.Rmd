---
title: "Corporate Landlords EDA - Avalon"
author: "Kate Ham"
date: "7/17/2020"
output: github_document
---

# Preface

Idea for this EDA came from Tenants Together's manual guide for corporate landlord ownership lookup [pdf](https://www.tenantstogether.org/sites/tenantstogether.org/files/Wall_St_Landlord_Participatory_Action_Research_Guide.pdf). In short, the guide says to find a landlord's website and get all the listing addresses. Then, go to a proptech data source like Property Radar to check ownership information.

## Packages

This EDA tries to speed up this process by scraping all the listing addresses from a landlord site with [`rvest`](https://github.com/tidyverse/rvest), then using dyplr with pre-downloaded CoreLogic data to quickly get owner information.

While using rvest, use the [SelectorGadget](https://selectorgadget.com/) Chrome extension to get the CSS selector for the addresses. Save the result as "css_selector".

We will also use the [`postmastr](https://github.com/slu-openGIS/postmastr) package to parse the addresses. This package is still in development so needs to be downloaded remotely.

**Limitations: The CoreLogic data downloaded is from 2019 and is only for the 9-county Bay Area. In addition, this analysis will exclusively look at [Avalon's properties in Northern California](https://www.avaloncommunities.com/northern-california).**

*Warning*: The `all9counties.rds` file is 3.6 GB.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
## Libraries
library(tidyverse)
library(rvest)
library(lubridate)
# install.packages("remotes")
#remotes::install_github("slu-openGIS/postmastr")
library(postmastr)
library(kableExtra)
```

```{r}
## Parameters

### Webscraping
url_data <- "https://www.avaloncommunities.com/northern-california" # Accessed 7-17-2020
css_selector <- ".address"
```

```{r, eval=FALSE}
### CoreLogic
corelogic <- read_rds(here::here("data-raw/all9counties.rds"))
best_vars <-   read_rds(here::here("data/best_vars.rds"))
file_data_dic <- here::here("data-raw/Bulk_Tax_Current_Layout w parcel level lat long_03102016.xlsx")
  # Property Indicator filter
RESIDENTIAL <- c(0:199)
  # recode function
recode_county <- function(county_fips) {
  county_fips %>% 
    recode(
      '06001' = "alameda",
      '06013' = "contra_costa", 
      '06041' = "marin",
      '06055' = "napa", 
      '06075' = "san_francisco",
      '06081' = "san_mateo",
      '06085' = "santa_clara",
      '06095' = "solano",
      '06097' = "sonoma" 
    )
}
```

# Webscraping

Note: If the html elements are in lists, check out this [thread](https://stackoverflow.com/questions/52650604/scrapping-li-elements-with-rvest).

```{r read}
address_data <- 
  url_data %>% 
  read_html() %>% 
  html_nodes(css = css_selector) %>% 
  html_text()
```

Next, save the address data in a tibble to make it easier to manage.

```{r addresses}
avalon <- 
  tibble(
    owner = "avalon",
    address = str_to_upper(address_data),
    access_date = Sys.Date()
  )
avalon %>% kable
```

According to the `postmastr` [guide](https://slu-opengis.github.io/postmastr/articles/postmastr.html), We first need to create the appropriate dictionaries for elements of the address.

```{r, eval=FALSE}
dict_ca <- 
  pm_dictionary(
    type = "state",
    filter = "CA",
    case = "upper",
    locale = "us"
  )

dict_cities <- 
  pm_dictionary(
    type = "city",
    filter = "CA",
    case = "upper",
    locale = "us"
  )

dict_dir <- 
  pm_dictionary(
    type = "directional",
    case = "upper"
  )

# I can't figure out how to tidy this...
dict_mode <- 
  pm_dictionary(
    type = "suffix",
    case = "upper"
  )
# get abbreviated street modes
dict_mode <- 
  dict_mode %>% 
  bind_rows(
    map(
      1, 
      ~ dict_mode %>% 
        mutate(suf.input = str_c(.$suf.input, "."))
    )
  )

```

We then parse out each element of the address and clean up the table a bit so it's easier to join with the CoreLogic data. Be sure to modify the function as necessary depending on the elements that are missing from the scraped addresses. There's definitely already some parsing errors that might be able to be fixed upon further examination.

```{r, eval=FALSE}
avalon <- 
  avalon %>% 
  pm_identify(var = "address") %>% 
  pm_parse(
    input = "full",
    address = "address",
    output = "full",
    keep_parsed = "yes",
    side = "right",
    keep_ids = TRUE,
    dir_dict = dict_dir,
    suffix_dict = dict_mode,
    city_dict = dict_cities,
    state_dict = dict_ca,
    locale = "us"
  ) %>%
  transmute(
    owner,
    address,
    access_date,
    house_num = pm.house,
    dir = str_to_upper(pm.preDir),
    street = str_to_upper(pm.street),
    mode = str_to_upper(pm.streetSuf),
    city = pm.city,
    zipcode = pm.zip
  )
avalon
```
